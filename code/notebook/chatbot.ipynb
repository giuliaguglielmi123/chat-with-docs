{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/giulia/Documents/giulia/chat-with-docs/code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from langchain.vectorstores import Chroma\n",
    "import os\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# OpenAIEmbeddings() was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. That's why I use langchain_openai instaed\n",
    "import langchain_openai\n",
    "import logging\n",
    "\n",
    "\n",
    "from utilities.customprompt import PROMPT\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "\n",
    "from langchain.chains.chat_vector_db.prompts import CONDENSE_QUESTION_PROMPT\n",
    "\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the llm model\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "k = 4\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "SYSTEM_TEMPLATE = \"\"\"\n",
    "Answer the user's questions based on the below context. \n",
    "If the context doesn't contain any relevant information to the question, don't make something up and just say \"I don't know\":\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\"\"\"\n",
    "\n",
    "question_answering_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            SYSTEM_TEMPLATE,\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.2)\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, question_answering_prompt)\n",
    "\n",
    "\n",
    "# Load documents from the specified directory\n",
    "loader = PyPDFLoader(\"docs/Naval Ravikant - The Almanack.pdf\")\n",
    "documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform words into numbers\n",
    "embeddings = langchain_openai.OpenAIEmbeddings(openai_api_key=api_key)\n",
    "\n",
    "# split the text to chuncks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Upload into the vector store\n",
    "vector_store = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k is the number of chunks to retrieve\n",
    "retriever = vector_store.as_retriever(k=4)\n",
    "question=\"What Naval think about love?\"\n",
    "docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Naval believes that love is one of the most important aspects of life, as he prioritizes health, love, and one's mission in that order. He values honesty and clarity in relationships, expressing that he appreciates not having to guess how someone feels about him or a situation. While the specific details of his thoughts on love are not explicitly mentioned in the context, it is clear that he values authenticity and direct communication in relationships.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "document_chain.invoke(\n",
    "    {\n",
    "        \"context\": docs,\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=question)\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_generator = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT, verbose=False)\n",
    "\n",
    "doc_chain = load_qa_with_sources_chain(llm, chain_type=\"stuff\", verbose=False, prompt=PROMPT)\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    return_source_documents=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'what Naval think about love?',\n",
       " 'chat_history': [],\n",
       " 'answer': \"Naval believes that love is a priority, along with health and one's mission. He also values a calm mind, a fit body, and a house full of love, and believes that these things cannot be bought, but must be earned.\",\n",
       " 'source_documents': [Document(page_content='NAVAL ’S WRITING ·  225Health, love, and your mission, in that order. Nothing else \\nmatters.', metadata={'page': 224, 'source': 'docs/Naval Ravikant - The Almanack.pdf'}),\n",
       "  Document(page_content='instinct for seeing through life’ s veneer has changed how I see \\nthe world.\\nI’ve learned an enormous amount from Naval. Reading, listening, \\nand applying his principles of wealth and happiness has given \\nme calm confidence on my path and taught me to enjoy every \\nmoment of this journey. Closely studying his career has shown \\nme how great things are accomplished through small, persistent \\nsteps, and how large an impact one individual can have.', metadata={'page': 17, 'source': 'docs/Naval Ravikant - The Almanack.pdf'}),\n",
       "  Document(page_content='124 · THE ALMANACK OF NAVAL RAVIKANTA calm mind, a fit body, and a house full of love.\\nThese things cannot be bought.\\nThey must be earned.', metadata={'page': 123, 'source': 'docs/Naval Ravikant - The Almanack.pdf'}),\n",
       "  Document(page_content='“successful” people out there. Be careful about modeling those, \\nas you will get all the bathwater with the baby.\\nI take Naval seriously because he:\\n → Questions nearly everything\\n → Can think from first principles\\n → Tests things well', metadata={'page': 13, 'source': 'docs/Naval Ravikant - The Almanack.pdf'})]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history=[]\n",
    "query='what Naval think about love?'\n",
    "\n",
    "chain.invoke({'question': query, 'chat_history': chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "k = 4\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Define the llm model\n",
    "#llm=langchain_openai.OpenAI(openai_api_key = api_key, model_name=\"gpt-3.5-turbo\", temperature=0.5,max_tokens=300)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.7)\n",
    "\n",
    "# Load documents from the specified directory\n",
    "loader = PyPDFLoader(\"docs/Naval Ravikant - The Almanack.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform words into numbers\n",
    "embeddings = langchain_openai.OpenAIEmbeddings(openai_api_key=api_key)\n",
    "\n",
    "# split the text to chuncks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Upload into the vector store\n",
    "vector_store = Chroma.from_documents(texts, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'what Naval think about love?',\n",
       " 'chat_history': [],\n",
       " 'answer': \"NAVAL believes that love is important and should be prioritized, along with health and one's mission. He also values the genuine love for reading as a superpower.\",\n",
       " 'source_documents': [Document(page_content='NAVAL ’S WRITING ·  225Health, love, and your mission, in that order. Nothing else \\nmatters.', metadata={'page': 224, 'source': 'docs/Naval Ravikant - The Almanack.pdf'}),\n",
       "  Document(page_content='NAVAL ’S WRITING ·  225Health, love, and your mission, in that order. Nothing else \\nmatters.', metadata={'page': 224, 'source': 'docs/Naval Ravikant - The Almanack.pdf'}),\n",
       "  Document(page_content='114 · THE ALMANACK OF NAVAL RAVIKANTLEARN TO LOVE TO READ\\n(Specific recommendations for books, blogs, and more are in \\n“Naval’s Recommended Reading” section.)\\nThe genuine love for reading itself, when cultivated, is a super -\\npower. We live in the age of Alexandria, when every book and \\nevery piece of knowledge ever written down is a fingertip away. \\nThe means of learning are abundant—it’s the desire to learn \\nthat is scarce.\\xa0[3]\\nReading was my first love.\\xa0[4]', metadata={'page': 113, 'source': 'docs/Naval Ravikant - The Almanack.pdf'}),\n",
       "  Document(page_content='114 · THE ALMANACK OF NAVAL RAVIKANTLEARN TO LOVE TO READ\\n(Specific recommendations for books, blogs, and more are in \\n“Naval’s Recommended Reading” section.)\\nThe genuine love for reading itself, when cultivated, is a super -\\npower. We live in the age of Alexandria, when every book and \\nevery piece of knowledge ever written down is a fingertip away. \\nThe means of learning are abundant—it’s the desire to learn \\nthat is scarce.\\xa0[3]\\nReading was my first love.\\xa0[4]', metadata={'page': 113, 'source': 'docs/Naval Ravikant - The Almanack.pdf'})]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a QA chain using an OpenAI object, a chain type, and a prompt template.\n",
    "question_generator = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT, verbose=False)\n",
    "\n",
    "doc_chain = load_qa_with_sources_chain(llm, chain_type=\"stuff\", verbose=False, prompt=PROMPT)\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "\n",
    "chain.invoke({\"question\": query, \"chat_history\": chat_history})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting unique sources\n",
    "unique_sources = set(map(lambda x: x.metadata[\"source\"], result['source_documents']))\n",
    "\n",
    "# Enumerating and formatting the sources\n",
    "sources = [f\"{idx}. {source}\" for idx, source in enumerate(unique_sources, start=1)]\n",
    "\n",
    "source_chunks=\"\\n\".join(f\"Chunck_number_{i}:{doc.page_content}\" for i, doc in enumerate(result['source_documents']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
