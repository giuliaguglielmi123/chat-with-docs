{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from langchain.document_loaders import UnstructuredPowerPointLoader, PyPDFLoader, UnstructuredWordDocumentLoader\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # by default get .env file \n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Libraries\n",
    "### Microsoft Graph API\n",
    "# Credential REQ000010741904\n",
    "# is a function that reads an environment variable's value.\n",
    "# Global variables\n",
    "client_id = os.getenv(\"O365_CLIENT_ID\")\n",
    "client_secret = os.getenv(\"O365_CLIENT_SECRET\")\n",
    "tenant_name = \"enelcom\"\n",
    "tenant_id = os.getenv(\"SHAREPOINT_TENANT_ID\")\n",
    "site_name = os.getenv(\"SHAREPOINT_SITE_NAME\")\n",
    "collection_id = os.getenv(\"SHAREPOINT_COLLECTION_ID\")\n",
    "subsite_id = os.getenv(\"SHAREPOINT_SUBSITE_ID\")  # This was missing in your original script\n",
    "sharepoint_site_id = f\"{tenant_name}.sharepoint.com,{collection_id},{subsite_id}\"\n",
    "document_library_id = os.getenv(\"SHAREPOINT_DOCUMENT_LIBRARY_ID\")\n",
    "account_name = os.getenv('BLOB_ACCOUNT_NAME')\n",
    "account_key = os.getenv('BLOB_ACCOUNT_KEY')\n",
    "connect_str = f\"DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key};EndpointSuffix=core.windows.net\"\n",
    "# container_name = \"documents/sharepoint\"\n",
    "destination_folder = \"documents\\\\sharepoint\"\n",
    "\n",
    "# Function to log messages\n",
    "log_folder = \"logs\"\n",
    "\n",
    "# list_doc_type = ['pptx', 'docx', 'pdf']\n",
    "# list_doc_type = ['docx']\n",
    "list_doc_type = ['pptx', 'docx', 'pdf']\n",
    "# sharepoint_folder = [\"how to\"]\n",
    "sharepoint_folder = [\"how to\", \"organization\", \"guidelines\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Giulia\\\\01_Projects\\\\ITS_AI\\\\chatbot_azure_test'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log function\n",
    "def log_message(message):\n",
    "    with open(os.path.join(log_folder, 'download_log.txt'), 'a', encoding='utf-8') as log_file:\n",
    "        log_file.write(message + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(log_folder, 'download_log.txt'), 'w', encoding='utf-8')as log_file:\n",
    "        log_file.write(f\"Date: {datetime.now().strftime(\"%Y-%d-%m\")} \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Microsoft Graph API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_url = f'https://login.microsoftonline.com/{tenant_id}/oauth2/v2.0/token'\n",
    "headers = {'Content-Type': 'application/x-www-form-urlencoded'}\n",
    "token_data = {\n",
    "    'grant_type': 'client_credentials',\n",
    "    'client_id': client_id,\n",
    "    'client_secret': client_secret,\n",
    "    'scope': 'https://graph.microsoft.com/.default'\n",
    "}\n",
    "token_r = requests.post(token_url, data=token_data, headers=headers)\n",
    "token = token_r.json().get('access_token')\n",
    "headers = {'Authorization': 'Bearer ' + token}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping from folder  how to   [GLOBAL] VPN PALO ALTO - EXTERNAL USERS - COMPANY ACCOUNT ISSUE.url\n",
      "Downloaded from  how to   Active Directory Management_v1.7.pptx\n",
      "Downloaded from  how to   ADFS Service request - english version.docx\n",
      "Downloaded from  how to   Application_pubblication_internet_2.pdf\n",
      "Downloaded from  how to   AWS Enterprise Support.pdf\n",
      "Downloaded from  how to   Bastion Host and Obsolete_RO-Apps_EN.pdf\n",
      "Downloaded from  how to   Bigdata Powercenter - How to use Service Requests.pdf\n",
      "Downloaded from  how to   Control-M Authorization.pptx\n",
      "Downloaded from  how to   Dynatrace Overview.pptx\n",
      "Downloaded from  how to   Enel_-_AWS_Architecture_v2.0.pdf\n",
      "Downloaded from  how to   Enel_-_AWS_Guidelines_RDS_v5.pdf\n",
      "Downloaded from  how to   Flavour PHP.pdf\n",
      "Downloaded from  how to   Gold-Applications_SLA-Measurement_DH-DSValidationPhase_v2-0 .pptx\n",
      "Downloaded from  how to   Guida SR SCA - Synthetic test (ETE).pptx\n",
      "Downloaded from  how to   HOW TO Fill a Internet Publishing Application SR V7.pdf\n",
      "Downloaded from  how to   How to Open an Incident - System Management.pptx\n",
      "Downloaded from  how to   How to populate  Operational _Incident Support Group.pdf\n",
      "Downloaded from  how to   Incident Alert - Authorization - EN - .pdf\n",
      "Downloaded from  how to   ITS support DHDS for switch AZ_v0.2.pdf\n",
      "Downloaded from  how to   Migration from SQLServer to RDS.pdf\n",
      "Downloaded from  how to   On Duty Management - User's guide - EN -.pdf\n",
      "Downloaded from  how to   OneIdentity_A2A.pdf\n",
      "Downloaded from  how to   OneIdentity_LinuxPamSessions.pdf\n",
      "Downloaded from  how to   Operational Instruction to Manage Planned Downtime Activities.docx\n",
      "Downloaded from  how to   PRESENT_ENEL_NOI-Dynatrace Integration_Netcool - Training Material.pptx\n",
      "Downloaded from  how to   Quick_Guide_VPN_GlobalProtect_PaloAlto_External User.pdf\n",
      "Downloaded from  how to   SCA - Attention or Support request .pptx\n",
      "Downloaded from  how to   SCA - SAP - DB Hana Largest Table.pdf\n",
      "Downloaded from  how to   SCA - SAP - DB Hana User Management (AWX Ansible).pdf\n",
      "Downloaded from  how to   SCA - SAP - Query DB Hana License (AWX Ansible).pdf\n",
      "Downloaded from  how to   Service Management Processes ITS ver 3.18_publ.pptx\n",
      "Downloaded from  how to   SOD ITS Catalog Use Guide Line_v4.5.pptx\n",
      "Downloaded from  how to   System Administrator​_EN.pptx\n",
      "Downloaded from  how to   Unplanned Outage Communication for GOLD Services_v09.pdf\n",
      "Downloaded from  how to   Using MFA on Safeguard.pdf\n",
      "Downloaded from  how to   WCM operational instruction V2.1.pptx\n",
      "Downloaded from  how to   Workload Change Manager Course for ENEL for USERS V9019 (1).pptx\n",
      "Downloaded from  organization   ARM TEMPLATE.pptx\n",
      "Downloaded from  organization   Automazione ISA.pptx\n",
      "Downloaded from  organization   DevOps Review.pptx\n",
      "Skipping from folder  organization   DevOps.mp4\n",
      "Downloaded from  organization   Incontri Tecnici I&TS #4 SC&A.pptx\n",
      "Downloaded from  organization   Incontri Tecnici2-Azure.pptx\n",
      "Downloaded from  organization   Internal Istio Workshop.pptx\n",
      "Downloaded from  organization   Introduction to CloudFormation.pdf\n",
      "Downloaded from  organization   Introduction to Lambda.pdf\n",
      "Downloaded from  organization   ITS _SMM_Organization-Activities.pptx\n",
      "Downloaded from  organization   ITS_Services.pdf\n",
      "Downloaded from  organization   PD_OP_34_GDS_APM.pdf\n",
      "Downloaded from  organization   Summary _SMM_SM-ITS Presentation.pptx\n",
      "Downloaded from  organization   THOR.pptx\n",
      "Downloaded from  organization   Training cloud interconnection and cnf.pptx\n",
      "Downloaded from  organization   TUP 2023 - Vademecum.pdf\n",
      "Downloaded from  organization   workshopdevops.pptx\n",
      "Skipping from folder  guidelines   ​​Azure Authentication.url\n",
      "Downloaded from  guidelines   ESE - LG05 - Standard Oracle.pdf\n",
      "Downloaded from  guidelines   ESE - LG06 - Best practices per Export-Import Oracle.pdf\n",
      "Skipping from folder  guidelines   File Transfert - Connect Direct.url\n",
      "Skipping from folder  guidelines   How to request TIBCO on SNOW.url\n",
      "Downloaded from  guidelines   ITS Standard Backup GUIDELINES.pdf\n",
      "Downloaded from  guidelines   ITS-SA managed technologies v4.pptx\n",
      "Skipping from folder  guidelines   Microservices Guidelines.url\n",
      "Downloaded from  guidelines   MicroServices ITS Catalog Use Basic Guide Line.pptx\n",
      "Downloaded from  guidelines   monitoring guide slides 2.8.pdf\n",
      "Downloaded from  guidelines   Monitoring_Guide_V9.11.pdf\n",
      "Downloaded from  guidelines   New way to access to Containers.pptx\n",
      "Downloaded from  guidelines   Observability Platform Tools Access.pdf\n",
      "Downloaded from  guidelines   Operational_Note_IIS_Kerberos_v4.1.docx\n",
      "Downloaded from  guidelines   SCA  - DSP Approval Process_en_release_plan.pptx\n",
      "Downloaded from  guidelines   SHAREPOINT_ENEL_ITS_SMM_DS_DH_Guide_v1.pdf\n",
      "Downloaded from  guidelines   Splunk4Rookies.pdf\n",
      "Downloaded from  guidelines   SWH-DHDS-1.2.pdf\n",
      "Downloaded from  guidelines   SWH-Guidelines1.2.pdf\n",
      "Downloaded from  guidelines   TEMPLATE-SWH-Guidelines rev2.7.pdf\n",
      "Skipping from folder  guidelines   TEMPLATE-SWH-New application rev2.7.dotx\n",
      "Skipping from folder  guidelines   TIBCO GUIDELINES.url\n",
      "Downloaded from  guidelines   Use of Azure as a SAML Identity Provider.pdf\n",
      "Downloaded from  guidelines   Working with Oracle database.pdf\n",
      "Downloaded from  guidelines   Working_with_PostgreSQL_Database.pdf\n"
     ]
    }
   ],
   "source": [
    "data_info=[]\n",
    "\n",
    "for folder in sharepoint_folder:\n",
    "\n",
    "    # create a new folder\n",
    "    folder_path = os.path.join(destination_folder, folder)\n",
    "\n",
    "    # check whether exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    file_url = f'https://graph.microsoft.com/v1.0/drives/{document_library_id}/root:/{folder}:/children'\n",
    "\n",
    "    response = requests.get(file_url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        folder_contents = json.loads(response.text)\n",
    "\n",
    "        # Loop through each item in the folder\n",
    "        for item in folder_contents['value']:\n",
    "            file_name = item['name']\n",
    "            file_weburl = item[\"webUrl\"] # url to the file\n",
    "            file_extension = file_name.split('.')[-1]\n",
    "\n",
    "            # Check the file extension and handle accordingly\n",
    "            if file_extension in list_doc_type:\n",
    "                file_url = item['@microsoft.graph.downloadUrl']\n",
    "                \n",
    "                # Download the file\n",
    "                file_response = requests.get(file_url, headers=headers)\n",
    "                if file_response.status_code == 200:\n",
    "    \n",
    "                    with open(os.path.join(folder_path, file_name) , 'wb') as f:\n",
    "                        f.write(file_response.content)\n",
    "                    log_message(f\"{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - folder {folder} Downloaded {file_name}\")\n",
    "                    print(\"Downloaded from \", folder, \" \",  file_name)\n",
    "\n",
    "                    # storing info documents like weburl, path and name document (will be used then to upload document into the blob storage\n",
    "                    # and to upload source into the vectordb)\n",
    "\n",
    "                    data_info.append({                    \n",
    "                        \"name\": file_name,\n",
    "                        \"webUrl\": file_weburl,\n",
    "                        \"path\": folder_path + \"\\\\\" + file_name,\n",
    "                        \"path_blob\": folder_path + \"\\\\\" + os.path.splitext(file_name)[0] + \".txt\"\n",
    "                    })\n",
    "                    \n",
    "                    with open(os.path.join(destination_folder, \"info_docs.json\"), mode=\"w\", encoding=\"utf-8\") as f:\n",
    "                        json.dump(data_info, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "                else:\n",
    "                    log_message(f\"{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - folder: {folder} Failed to download {file_name}\")\n",
    "                    print(\"Failed to download from \", folder, \" \", file_name)\n",
    "            else:\n",
    "                # If the file is not one of the desired types, skip to the next item\n",
    "                log_message(f\"{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} - folder {folder} Skipping {file_name}, not a target file type.\")\n",
    "                print(\"Skipping from folder \", folder, \" \", file_name)\n",
    "\n",
    "    else:\n",
    "        log_message(f\"{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} Failed to access folder {folder}: {response.status_code}\")\n",
    "        print(\"Failed to access folder\")\n",
    "        print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading ADFS Service request - english version.docx from documents\\sharepoint\\how to\\ADFS Service request - english version.docx\n",
      "uploading Operational Instruction to Manage Planned Downtime Activities.docx from documents\\sharepoint\\how to\\Operational Instruction to Manage Planned Downtime Activities.docx\n"
     ]
    }
   ],
   "source": [
    "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "\n",
    "\n",
    "def process_and_upload_file(file_path):\n",
    "    # Extract the file name and extension\n",
    "    file_name = os.path.basename(file_path)\n",
    "\n",
    "    file_extension = file_name.split('.')[-1]\n",
    "\n",
    "    print(f\"uploading {file_name} from {file_path}\")\n",
    "\n",
    "    # Initialize the document\n",
    "    doc = None\n",
    "\n",
    "    # Check the file extension and call the appropriate loader\n",
    "    if file_extension == 'pptx':\n",
    "        loader = UnstructuredPowerPointLoader(file_path)\n",
    "        doc = loader.load()\n",
    "    elif file_extension == 'docx':\n",
    "        loader = UnstructuredWordDocumentLoader(file_path)\n",
    "        doc = loader.load()\n",
    "    elif file_extension == 'pdf':\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        doc = loader.load()\n",
    "\n",
    "    # Process the document if it was successfully loaded\n",
    "    if doc:\n",
    "        all_pages = \"\\n\".join(page.to_json()[\"kwargs\"][\"page_content\"] for page in doc)\n",
    "\n",
    "        # Set blob name to the current file name with .txt extension\n",
    "        blob_name = os.path.splitext(file_name)[0] + \".txt\"\n",
    "\n",
    "        # Create a ContainerClient\n",
    "        container_client = blob_service_client.get_container_client(os.path.dirname(file_path).replace(\"\\\\\", \"/\"))\n",
    "\n",
    "        # Create a BlobClient to upload the text file\n",
    "        blob_client = container_client.get_blob_client(blob_name)\n",
    "\n",
    "        # Upload to Azure Blob Storage\n",
    "        blob_client.upload_blob(all_pages, overwrite=True)\n",
    "\n",
    "# Start the process from the 'docs' directory\n",
    "for path in data:\n",
    "    process_and_upload_file(path[\"path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run it from the \n",
    "if __name__ == \"__main__\":\n",
    "    run_sharepoint_tasks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
