{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "# OpenAIEmbeddings() was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. That's why I use langchain_openai instaed\n",
    "import langchain_openai\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "\n",
    "from langchain.chains.chat_vector_db.prompts import CONDENSE_QUESTION_PROMPT\n",
    "\n",
    "from langchain.chains.llm import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Projects\\\\chatbot\\\\code'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.customprompt import PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = langchain_openai.OpenAIEmbeddings(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"docs/Naval Ravikant - The Almanack.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the text to chuncks of of size 1000\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=langchain_openai.OpenAI(openai_api_key = api_key, model_name=\"text-davinci-003\", temperature=0,max_tokens=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic answer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_generator = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT, verbose=False)\n",
    "\n",
    "doc_chain = load_qa_with_sources_chain(llm, chain_type=\"stuff\", verbose=False, prompt=PROMPT)\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "question = \"ciao\"\n",
    "result = chain.invoke({\"question\": question, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'ciao',\n",
       " 'chat_history': [],\n",
       " 'answer': ' Hi there! How can I help you?',\n",
       " 'source_documents': [Document(page_content='162 · THE ALMANACK OF NAVAL RAVIKANTronment. It leads to allergies and an untrained immune system. \\nThis is known as the hygiene hypothesis. We’re evolved to live \\nin much smaller tribes and to have more family around us. I \\npartially grew up in India, and in India, everybody is in your \\nbusiness. There’ s a cousin, an aunt, an uncle who is in your face, \\nwhich makes it hard to be depressed, because you are never \\nalone. (I’m not referring to people with chemical depression. \\nI’m talking more about the existential angst and malaise teen -\\nagers seem to go through.) But on the other hand, you have no \\nprivacy, so you can’t be free. There are trade-offs.\\nWe’re not meant to check our phone every five minutes. The \\nconstant mood swings of getting a “like” then an angry com -\\nment makes us into anxious creatures. We evolved for scarcity \\nbut live in abundance. There’ s a constant struggle to say no \\nwhen your genes always want to say yes. Yes to sugar. Yes to \\nstaying in this relationship. Yes to alcohol. Yes to drugs. Yes, \\nyes, yes. Our bodies don’t know how to say no.\\xa0[8]\\nWhen everyone is sick, we no longer consider it a disease.\\nDIET\\nOutside of math, physics, and chemistry, there isn’t much \\n“settled science.” We’re still arguing over what the optimal \\ndiet is.\\nDo you have an opinion on the ketogenic diet?', metadata={'page': 161, 'source': 'docs/Naval Ravikant - The Almanack.pdf'}),\n",
       "  Document(page_content='162 · THE ALMANACK OF NAVAL RAVIKANTronment. It leads to allergies and an untrained immune system. \\nThis is known as the hygiene hypothesis. We’re evolved to live \\nin much smaller tribes and to have more family around us. I \\npartially grew up in India, and in India, everybody is in your \\nbusiness. There’ s a cousin, an aunt, an uncle who is in your face, \\nwhich makes it hard to be depressed, because you are never \\nalone. (I’m not referring to people with chemical depression. \\nI’m talking more about the existential angst and malaise teen -\\nagers seem to go through.) But on the other hand, you have no \\nprivacy, so you can’t be free. There are trade-offs.\\nWe’re not meant to check our phone every five minutes. The \\nconstant mood swings of getting a “like” then an angry com -\\nment makes us into anxious creatures. We evolved for scarcity \\nbut live in abundance. There’ s a constant struggle to say no \\nwhen your genes always want to say yes. Yes to sugar. Yes to \\nstaying in this relationship. Yes to alcohol. Yes to drugs. Yes, \\nyes, yes. Our bodies don’t know how to say no.\\xa0[8]\\nWhen everyone is sick, we no longer consider it a disease.\\nDIET\\nOutside of math, physics, and chemistry, there isn’t much \\n“settled science.” We’re still arguing over what the optimal \\ndiet is.\\nDo you have an opinion on the ketogenic diet?', metadata={'page': 161, 'source': 'docs/Naval Ravikant - The Almanack.pdf'}),\n",
       "  Document(page_content='24 · THE ALMANACK OF NAVAL RAVIKANTBACKGROUND\\nI grew up in a single-parent household with my mom working, \\ngoing to school, and raising my brother and me as latchkey \\nkids. We were very self-sufficient from a very early age. There \\nwas a lot of hardship, but everyone goes through hardship. It \\ndid help me in a number of ways.\\nWe were poor immigrants. My dad came to the US—he was a \\npharmacist in India. But his degree wasn’t accepted here, so \\nhe worked in a hardware store. Not a great upbringing, you \\nknow. My family split up.\\xa0[47]\\nMy mother uniquely provided, against the background of hard-\\nship, unconditional and unfailing love. If you have nothing \\nin your life, but you have at least one person that loves you \\nunconditionally, it’ll do wonders for your self-esteem.\\xa0[8]\\nWe were in a part of New York City that isn’t very safe. Basically, \\nthe library was my after-school center. After I came back from \\nschool, I would just go straight to the library and hang out \\nthere until they closed. Then, I would come home. That was \\nmy daily routine.\\xa0[8]\\nWe moved to the US when we were very young. I didn’t have \\nmany friends, so I wasn’t very confident. I spent a lot of time \\nreading. My only real friends were books. Books make for great \\nfriends, because the best thinkers of the last few thousand \\nyears tell you their nuggets of wisdom.\\xa0[8]\\nMy first job was with an illegal catering company in the back \\nof a van delivering Indian food when I was fifteen. Even when \\nI was younger, I had a paper route and I washed dishes in the \\ncafeteria.', metadata={'page': 23, 'source': 'docs/Naval Ravikant - The Almanack.pdf'}),\n",
       "  Document(page_content='24 · THE ALMANACK OF NAVAL RAVIKANTBACKGROUND\\nI grew up in a single-parent household with my mom working, \\ngoing to school, and raising my brother and me as latchkey \\nkids. We were very self-sufficient from a very early age. There \\nwas a lot of hardship, but everyone goes through hardship. It \\ndid help me in a number of ways.\\nWe were poor immigrants. My dad came to the US—he was a \\npharmacist in India. But his degree wasn’t accepted here, so \\nhe worked in a hardware store. Not a great upbringing, you \\nknow. My family split up.\\xa0[47]\\nMy mother uniquely provided, against the background of hard-\\nship, unconditional and unfailing love. If you have nothing \\nin your life, but you have at least one person that loves you \\nunconditionally, it’ll do wonders for your self-esteem.\\xa0[8]\\nWe were in a part of New York City that isn’t very safe. Basically, \\nthe library was my after-school center. After I came back from \\nschool, I would just go straight to the library and hang out \\nthere until they closed. Then, I would come home. That was \\nmy daily routine.\\xa0[8]\\nWe moved to the US when we were very young. I didn’t have \\nmany friends, so I wasn’t very confident. I spent a lot of time \\nreading. My only real friends were books. Books make for great \\nfriends, because the best thinkers of the last few thousand \\nyears tell you their nuggets of wisdom.\\xa0[8]\\nMy first job was with an illegal catering company in the back \\nof a van delivering Indian food when I was fifteen. Even when \\nI was younger, I had a paper route and I washed dishes in the \\ncafeteria.', metadata={'page': 23, 'source': 'docs/Naval Ravikant - The Almanack.pdf'})]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Hi there! How can I help you?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. docs/conda-cheatsheet.pdf']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting unique sourcess\n",
    "unique_sources = set(map(lambda x: x.metadata[\"source\"], result['source_documents']))\n",
    "\n",
    "# Enumerating the sources\n",
    "sources = [f\"{idx}. {source}\" for idx, source in enumerate(unique_sources, start=1)]\n",
    "sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semantic_answer_lang_chain(prompt, chat_history):\n",
    "    \n",
    "    # Log a message indicating that the function has started\n",
    "    # LOGGER.info(f\"Start answering based on prompt: {prompt}.\")\n",
    "    \n",
    "    # Create a prompt template using a template from the config module and input variables\n",
    "    \n",
    "    # Load a QA chain using an OpenAI object, a chain type, and a prompt template.\n",
    "    question_generator = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT, verbose=False)\n",
    "\n",
    "    doc_chain = load_qa_with_sources_chain(llm, chain_type=\"stuff\", verbose=False, prompt=PROMPT)\n",
    "\n",
    "    chain = ConversationalRetrievalChain(\n",
    "        retriever=vector_store.as_retriever(),\n",
    "        question_generator=question_generator,\n",
    "        combine_docs_chain=doc_chain,\n",
    "        return_source_documents=True,\n",
    "    )\n",
    "\n",
    "    # Log a message indicating the number of chunks to be considered when answering the user's query.\n",
    "    # LOGGER.info(f\"The top {config.k} chunks are considered to answer the user's query.\")\n",
    "    \n",
    "\n",
    "    result = chain.invoke({\"question\": prompt, \"chat_history\": chat_history})\n",
    "\n",
    "    # Extracting unique sources\n",
    "    unique_sources = set(map(lambda x: x.metadata[\"source\"], result['source_documents']))\n",
    "\n",
    "    # Enumerating and formatting the sources\n",
    "    sources = [f\"{idx}. {source}\" for idx, source in enumerate(unique_sources, start=1)]\n",
    "\n",
    "    source_chunks=\"\\n\".join(f\"Chunck_number_{i}:{doc.page_content}\" for i, doc in enumerate(result['source_documents']))\n",
    "    \n",
    "    # Log a message indicating the answer that was generated\n",
    "    # LOGGER.info(f\"The returned answer is: {result['answer']}\")\n",
    "    \n",
    "    # Log a message indicating that the function has finished and return the answer.\n",
    "    # LOGGER.info(f\"Answering module over.\")\n",
    "\n",
    "    return prompt, result['answer'], sources, source_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input, result, sources, source_chunks = get_semantic_answer_lang_chain(\"ciao\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Hi there! How can I help you?'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-qna-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
